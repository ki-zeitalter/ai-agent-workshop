{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph - Eine Einführung\n",
    "\n",
    "Bis jetzt haben wir uns mit einem einzigen Agenten zufrieden gegeben. Aber wir können die Power der Agenten multiplizieren, wenn wir uns ein Agentensystem bauen!\n",
    "Stell dir vor, du hast ein System, in dem für jede Aufgabe ein spezialisierter Agent zuständig ist. Komplexe Aufgaben werden z.B. durch einen Planer-Agent in Teilaufgaben heruntergebrochen und auf andere spezialisierte Agenten verteilt. Ein Koordinator kümmert sich um die Zusammenarbeit und trägt die Einzelergebnisse zusammen.\n",
    "\n",
    "Das ist meines Erachtens die Zukunft. Stand heute Mitte 2024 gibt es diese Systeme schon, wenn auch nicht immer perfekt funktionierend. Aber die Entwicklung geht rasant voran und ich bin überzeugt, dass wir bald sehr gute Agentensysteme haben werden.\n",
    "\n",
    "Aber so ein System ist komplex und es wäre sicher nicht sinnvoll das alles selber programmieren zu wollen. Deswegen möchten wir LangGraph kennenlernen und nutzen.\n",
    "\n",
    "## Was ist LangGraph?\n",
    "\n",
    "Laut der Beschreibung von den LangGraph-Machern selbst: \n",
    "> \"LangGraph is a library for building stateful, multi-actor applications with LLMs, used to create agent and multi-agent workflows. \"\n",
    "\n",
    "Also handelt es sich um eine Bibliothek mit der wir Multi-Agenten Systeme (Agent Swarm) und Workflows bauen können! Mehr Details hier: https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "Was ist der Unterschied zu anderen Agenten-Frameworks wie AutoGen und Co.? LangGraph ist viel mehr Low-Level, d.h. man hat wesentlich mehr Kontrolle darüber, was und wie ausgeführt wird. Die anderen Frameworks hingegen verstecken die Logik. Oft definiert man dort, welche Agenten es gibt und welche Rollen sie haben. Die Art und Weise, wie sie interagieren etc. ist praktisch eine Blackbox.\n",
    "Nachteil: LangGraph ist schwerer zu lernen.\n",
    "\n",
    "Wir werden auch gleich sehen, dass die Programmierung eines Agentensystems auf Basis von LangGraph viel mit der Definition eines Workflowsystems zu tun hat.\n",
    "Das Prinzip ist, dass KI (LLM ) dazu verwendet wird Entscheidungen zu treffen und Aktionen auszuführen, basierend auf dem Kontext.\n",
    "\n",
    "Ein paar Zeilen Code sagen mehr als tausend Worte (berühmtes Zitat von S. Grünheit)... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir wollen erstmal LangGraph ohne KI mal anschauen... einfach um das Gefühl zu bekommen, wie es tickt... Aber erstmal müssen wir LangGraph installieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt bauen wir uns einen kleinen Graph. Dieser Graph macht zwar nichts besonders sinnvolles, aber er zeigt die Grundstruktur!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessageGraph, START, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Wir erstellen einen MessageGraph. Das ist ein Graph, dessen \"State\" aus Messages besteht\n",
    "graph = MessageGraph()\n",
    "\n",
    "def modify_message(input: list[HumanMessage]):\n",
    "    input[-1].content = input[-1].content + \" - wurde geändert\"\n",
    "    return input\n",
    "\n",
    "# Wir fügen zwei Nodes hinzu, die die Nachrichten verändern\n",
    "graph.add_node(\"Node A\", modify_message)\n",
    "graph.add_node(\"Node B\", modify_message)\n",
    "graph.add_node(\"Node C\", modify_message)\n",
    "\n",
    "graph.add_edge(START, \"Node A\")\n",
    "graph.add_edge(\"Node A\", \"Node B\")\n",
    "graph.add_edge(\"Node A\", \"Node C\")\n",
    "\n",
    "graph.add_edge(\"Node B\", END)\n",
    "graph.add_edge(\"Node C\", END)\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(runnable.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke([HumanMessage(\"Hallo Welt!\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Grundbausteine\n",
    "\n",
    "LangGraph kennt drei wesentliche Grundbausteine: _Node_, _Edge_ und _State_. Schauen wir uns diese mal genauer an.\n",
    "\n",
    "### Node\n",
    "Eine Funktion (Runnable) die den _State_ ändert und zurück gibt. Ein _Node_ bekommt einen _State_ als Eingabeparameter und entscheidet anhand des _State_ was zu tun ist und führt ggfs. irgendwelche Operationen aus. Anschliessend wird der _State_ geändert und zurückgeben. \n",
    "\n",
    "### Edge\n",
    "_Edges_ verbinden die _Nodes_. Es gibt auch _Conditional-Edges_ die einen Kontrollfluss erlauben.\n",
    "\n",
    "### State\n",
    "_State_ beinhaltet die Daten, die von den _Nodes_ angepasst und zurückgegeben werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasst uns die _Conditional-Edges_ mal anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessageGraph, START, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "def mache_etwas_mit_nachrichten(input: list[HumanMessage]):\n",
    "    print(\"Mache etwas mit Nachrichten\")\n",
    "    return input\n",
    "\n",
    "def fuege_welt_hinzu(input: list[HumanMessage]):\n",
    "    input[-1].content = input[-1].content + \" Welt!\"\n",
    "    return input\n",
    " \n",
    "def ist_hallo_dann_welt(input: list[HumanMessage]):\n",
    "    if input[-1].content == \"Hallo\":\n",
    "        return \"Node B\"\n",
    "    else:\n",
    "        return \"Node C\"\n",
    "\n",
    "# Wir fügen zwei Nodes hinzu, die die Nachrichten verändern\n",
    "graph.add_node(\"Node A\", mache_etwas_mit_nachrichten)\n",
    "graph.add_node(\"Node B\", fuege_welt_hinzu)\n",
    "graph.add_node(\"Node C\", mache_etwas_mit_nachrichten)\n",
    "\n",
    "graph.add_edge(START, \"Node A\")\n",
    "graph.add_conditional_edges(\"Node A\", ist_hallo_dann_welt)\n",
    "\n",
    "# Hinweis: bei add_conditional_edges können wir auch ein Mapping von Rückgabewert auf Nodes angeben\n",
    "# graph.add_conditional_edges(\"Node A\", ist_hallo_dann_welt, { \"Node B\": \"Node B\", \"Node C\": \"Node C\" })\n",
    "\n",
    "graph.add_edge(\"Node B\", END)\n",
    "graph.add_edge(\"Node C\", END)\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(runnable.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke([HumanMessage(\"Hallo\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke([HumanMessage(\"Hi\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok soweit so gut... lass uns das etwas aufbohren und eine Zyklus einbauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessageGraph, START, END\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "graph = MessageGraph()\n",
    "\n",
    "def mache_etwas_mit_nachrichten(input: list[HumanMessage]):\n",
    "    input.append(HumanMessage(\"Blabla\"))\n",
    "    return input\n",
    " \n",
    "def pruefe_laenge(input: list[HumanMessage]):\n",
    "    if len(input) > 5:\n",
    "        return \"Reicht!\"\n",
    "    else:\n",
    "        return \"Komm geht noch weiter!\"\n",
    "\n",
    "\n",
    "graph.add_node(\"Node A\", mache_etwas_mit_nachrichten)\n",
    "\n",
    "graph.add_edge(START, \"Node A\")\n",
    "graph.add_conditional_edges(\"Node A\", pruefe_laenge, { \"Reicht!\": END, \"Komm geht noch weiter!\": \"Node A\" })\n",
    "\n",
    "runnable = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(runnable.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable.invoke([HumanMessage(\"Hallo\")])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir haben jetzt die Grundbausteine kennengelernt, also lass uns jetzt etwas sinnvolles machen: lasst uns das Hallo-Welt der KIs bauen: einen Chatbot!\n",
    "\n",
    "Der Chatbot soll solange Fragen entgegen nehmen und beantworten, bis der Benutzer \"exit\" eingibt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_input(state: State):\n",
    "    user_input = input(\"User: \")\n",
    "    state[\"messages\"].append(HumanMessage(user_input))\n",
    "    return state\n",
    "\n",
    "def chatbot(state: State):\n",
    "    response = model.invoke(state[\"messages\"])\n",
    "    print(\"Bot:\", response.content)\n",
    "\n",
    "    state[\"messages\"].append(response)\n",
    "\n",
    "    return state\n",
    "\n",
    "def is_end(state: State):\n",
    "    if(state[\"messages\"][-1].content == \"exit\"):\n",
    "        return \"end\"\n",
    "    else:\n",
    "        return \"continue\"\n",
    "    \n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"get_user_input\", get_user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"get_user_input\")\n",
    "graph_builder.add_conditional_edges(\"get_user_input\", is_end, { \"end\": END, \"continue\": \"chatbot\" })\n",
    "graph_builder.add_edge(\"chatbot\", \"get_user_input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok zugegeben, das war eine Menge Code für einen Chatbot!\n",
    "\n",
    "Aber es zeigt zumindest einigermaßen, wie LangGraph tickt. Wir haben also offensichtlich einen Grafen, wo die Knoten Agentenfunktionen abbilden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
