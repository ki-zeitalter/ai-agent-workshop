{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Agenten\n",
    "KI Agenten sind laut vielen Experten das nächste große Ding in Sachen KIs. Ganz unabhängig davon, ob das stimmt, können (autonome) KI Agenten hilfreich sein und es lohnt sich, sich damit auseinander zu setzen.\n",
    "Meiner Einschätzung nach erweitern KI Agenten das Spektrum an Werkzeugen, die man zum Lösen von Aufgaben benötigt. Diese ermöglichen auch Aufgaben zu löschen, die zuvor eigentlich nicht automatisierbar waren.\n",
    "\n",
    "Dennoch, bei aller Euphorie, muss man sagen, dass Stand jetzt autonome Agenten noch in den Kinderschuhen stecken und häufig Fehler begehen. Komplexe Aufgaben sind also noch in weiter Ferne.\n",
    "\n",
    "Heute schauen wir uns an, wie man Agenten erstellt und wozu sie gut sein könnten. Wir beginnen mit sehr einfachen Formen und steigern uns dann und setzen das Agentenframework LangGraph ein.\n",
    "\n",
    "\n",
    "## Was sind denn Agenten überhaupt?\n",
    "\n",
    "Die Definitionen, was ein Agent ist, gehen wie so oft stark auseinander. Wo sich die meisten jedoch einig sind, ist dass wenn man der KI Werkzeuge zur Verfügung stellt und die KI selbst entscheidet, wann sie diese Werkzeuge einsetzen möchte, die erste Stufe eines Agenten erreicht ist.\n",
    "Es gibt aber je nach Definition auch Agenten ohne Werkzeuge, also z.B. Agenten, die durch Prompting-Techniken erzeugt werden. \n",
    "\n",
    "Meist weist man einem Agenten eine Rolle zu, z.B. Organisator, Qualitätssicherer, Coder usw. Der Hintergrund ist der, dass Sprachmodelle häufig besser performen, wenn man sie in eine Rolle versetzt. In Agentensystemen, hat man also meist ein paar Agenten mit unterschiedlichen Rollen.\n",
    "In diesen Systemen tauschen die Agenten Daten aus, sei es dadurch, dass sie einen Prompt mit allen notwenigen Informationen bekommen und die Antwort wird z.B. einen anderen Agenten übergeben, oder z.B. durch einen gemeinsamen Speicher, auf den jeder Agent Zugriff hat.\n",
    "\n",
    "Gibt man einer KI die Möglichkeit Werkzeuge zu nutzen, läuft das häufig so ab, dass die KI die Ausführung anfragt und jemand oder etwas führt das Werkzeug aus und übergibt das Ergebnis wiederum an die KI, die dann damit arbeiten kann. D.h. die KI kann nicht einfach selbst etwas ausführen. Allerings bieten Agentensysteme die Möglichkeit an, dass diese Tool-Anfragen automatisch ausgeführt werden, ohne dass ein Mensch die Ausführung genehmigen muss oder gar selbst ausführen muss. Hier sprechen wir dann von *autonomen* Agenten. Häufig kombiniert man das aber mit _Human-In-The-Loop_ Ansätzen. D.h. bei kritischen Ausführungen wird ein Mensch erstmal um Erlaubnis gebeten. Auch wird das genutzt um z.B. zu entscheiden, wie etwas weitergehen soll, im Sinne von entweder Weg A, B oder C z.B. Oder um weitere Informationen abzufragen.\n",
    "\n",
    "Bei Systemen mit mehreren Agenten kann man für jeden Agent unterschiedliche Modelle verwenden. So kann man für jede Aufgabe das beste Modell auswählen. Während z.B. der Organisator-Agent ein Modell einsetzt, das gut logisch kombinieren kann, setzt der Coder ein Modell ein, das besonders gut Code produzieren kann.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Wie funktioniert das mit den Tools? Die KI, also das Sprachmodell, kann nicht selbst Funktionen oder ähnliches ausführen. Aber die KI kann darum bitten.\n",
    "\n",
    "Wenn man der KI also sagt, dass ihr Tools zur Verfügung stehen und man außerdem beschreibt, welche Argumente die Tools benötigen, dann kann die KI sich dafür entscheiden. In der Tat werden die Modelle darauf trainiert. Der Chat-Request an Chat-GPT (also die direkte OpenAI-Schnittstelle) enthält sogar einen besonderen Bereich außerhalb des Prompts für die Tools. Man übergibt dabei einen Namen des Tools und ganz wichtig eine Beschreibung, wofür das Tool gut sein soll. Die Beschreibung dient der KI dazu zu verstehen, was das Tool kann. Dann listet man die erwarteten Parameter auf. Auch hier mit Namen, Datentyp und Beschreibung. Und klar, die Beschreibung erklärt der KI wozu der Parameter gut ist.\n",
    "\n",
    "\n",
    "Das Ganze können wir mal kurz über einen simplen Prompt simulieren. Nehmen wir das allererste Beispiel, das wir programmiert haben und passen es an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "model = AzureChatOpenAI(openai_api_version=\"2024-05-01-preview\", azure_deployment=\"gpt-4o\", temperature=0.5)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(\"Du bist ein hilfreicher Chatbot. Falls du nach der Uhrzeit gefragt wirst, dann kannst du ein Tool namens 'datetime' verwenden.\"\n",
    "                  \"Wenn du das Tool brauchst, dann antworte ausschließlich mit 'datetime'.\"),\n",
    "    HumanMessage(\"Wieviel Uhr ist es?\"),\n",
    "]\n",
    "\n",
    "response_text = model.invoke(messages)\n",
    "\n",
    "if response_text.content == \"datetime\":\n",
    "    import datetime\n",
    "    current_time = datetime.datetime.now().strftime(\"%d-%m-%Y %H:%M\")\n",
    "\n",
    "    messages.append(AIMessage(f\"Antwort vom Tool ist: {current_time}. Beantworte jetzt die Frage des Nutzers\"))\n",
    "\n",
    "    response_text = model.invoke(messages)\n",
    "\n",
    "response_text.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das funktioniert zwar, aber es wäre doch sehr mühsam, wenn wir das jedes mal so machen müssten.\n",
    "\n",
    "Lasst uns also anschauen, was LangChain zu bieten hat. Hierfür werden wir allerdings noch nicht die Agenten-Funktionalität nutzen.\n",
    "Das Stichwort heißt _Tools_. Wir können also Tools, also Werkzeuge, anlegen bzw. anbieten und LangChain kümmert sich um den Rest. Es gibt wie immer zahlreiche fertige Tools, die man einsetzen kann.\n",
    "\n",
    "Erstmal müssen wir aber etwas installieren, nämlich DuckDuckGo-Search. Das wollen wir nämlich als Tool in unserer kleinen Anwendung nutzen!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install duckduckgo-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erstmal starten wir mit der Initialisierung. Wir importieren das Tool, das wir gleich nutzen möchten und legen uns davon eine Instanz an.\n",
    "Wir testen auch, ob das Tool auch so funktioniert, d.h. ohne es in den Workflow mit der KI einzubinden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "search.run(\"Der schnellste Vogel der Welt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist schon mal cool, aber etwas mehr Informationen wären auch gut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import DuckDuckGoSearchResults\n",
    "\n",
    "search = DuckDuckGoSearchResults()\n",
    "\n",
    "search.run(\"Der schnellste Vogel der Welt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt bekommen wir auch Quellenangaben!\n",
    "\n",
    "Wie weiß jetzt die KI, wofür das Tool denn gut ist? Wir haben ja gelernt, dass jedes Tool eine Beschreibung braucht, damit die KI weiß wie und wofür es zu nutzen ist.\n",
    "Lass uns das mal ansehen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok bis jetzt haben wir das Tool praktisch selbst ausgeführt. Jetzt wollen wir es der KI an die virtuelle Hand geben. Wir werden später bei den Agenten sehen, dass es etwas eleganter geht, als das was gleich folgt.\n",
    "\n",
    "Jetzt ist es nämlich so, dass nicht jedes KI-Modell so gut in der Lage ist mit Tools umzugehen. OpenAIs ChatGPT ist z.B. extra dafür trainiert worden und man hat den Tools sogar einen extra Platz in der API gewidmet. Da kann man nämlich neben der Prompthistorie auch Tools mitgeben. Dort heißen sie allerdings _Functions_.\n",
    "Die _Functions_ sind eine Liste von Funktionen, wie der Name schon andeutet, wo man Name, Beschreibung und Parameter angibt. Vermutlich werden diese Angaben irgendwie automatisch in den System-Prompt der KI eingefügt, sodass die KI weiß welche Tools da sind.\n",
    "\n",
    "LangChain können wir dazu bringen, diese Funktionalität zu nutzen. Das schauen wir uns jetzt mal an..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "\n",
    "\n",
    "tools = [search]\n",
    "functions = [convert_to_openai_function(t) for t in tools]\n",
    "functions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, also offenbar gibt es eine Konvererfunktion, die aus den LangChain-Tools OpenAI-Functions macht.\n",
    "\n",
    "Jetzt können wir die _Functions_ auch bei der Konversation übergeben. Jetzt brauchen wir nur einen Prompt, der die KI dazu veranlasst dieses Tool zu nutzen und nicht einfach aus dem eigenen Trainingsdaten antwortet. Das geht am einfachsten, wenn man nach aktuellen Ereignissen fragt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = model.invoke(\n",
    "    [HumanMessage(content=\"Wie viel kostet das Maß Bier auf dem Münchener Oktoberfest im Jahr 2024?\")], functions=functions\n",
    ")\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahh ok! Was ist passiert? Nun, ChatGPT hat erkannt, dass wir suchen müssen und möchte gerne, dass wir das Tool _duckduckgo_results_json_ ausführen. Es gibt uns auch dafür die notwendigen Parameter mit. \n",
    "\n",
    "Jetzt müssten wir eigentlich loslegen und das ganze ausprogrammieren. D.h. wir müssten uns eine Routine bauen, die erkennt, welche Funktion ausgeführt werden soll. Dann müsste das Ergebnis als _ToolMessage_ an die KI übergeben werden, die dann daraus ihre finale Antwort baut.\n",
    "\n",
    "Wer möchte, kann das gerne als Übung machen. Aber das Ganze müssen wir doch nicht selbst erfinden, denn LangChain hat das ja schon eingebaut! Nämlich als Agent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier geht es zum nächsten Abschnitt: Erster Agent: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ki-zeitalter/ai-agent-workshop/blob/main/06_erster_agent.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
