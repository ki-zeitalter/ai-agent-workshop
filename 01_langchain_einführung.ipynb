{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Es wird Zeit anzufangen...\n","\n","Die meisten KI-Anbieter bieten eine eigene API zum Kommunizieren an. Diese sind meist ziemlich \"low-level\", d.h. manche Komfort-Funktion muss man selber entwickeln. Die APIs sind häufig vom Anbieter zu Anbieter ähnlich, aber nicht kompatibel.\n","In den meisten Fällen handelt es sich um REST-Endpunkte und JSON als Datenprotokoll. Eigentlich immer muss man einen API-Key mitgeben, den man bei dem Anbieter bekommt. Die Nutzung kostet dann pro verbrauchter Token.\n","\n","Starten wir mit einer LangChain-Einführung. \n","\n","### Was ist LangChain?\n","LangChain ist ein Framework um programmatisch mit KIs zu kommunizieren. In seiner einfachsten Form ist es eine einheitliche API für alle möglichen Sprachmodelle. Zusätzlich bietet es zahlreiche Utilities und Helferlein für alle erdenklichen Aufgaben rund um das Thema KI. Der Vorteil bei der Nutzung von solchen Frameworks ist, dass man sich weniger stark an den Anbieter von dem jeweiligen KI-Modells bindet, die ja meist ihre eigenen APIs anbieten. So kann man sehr leicht bestehenden Code auf ein anderes Modell jagen, ohne dabei viel anpassen zu müssen.\n","\n","LangChain ist eines der am stärksten verbreiteten Frameworks. Das hat sicher damit zu tun, dass LangChain relativ früh am Anfang des Hypes, der nach dem Launch von ChatGPT losgeganen ist, zur Verfügung stand. Wegen der Verbreitung und der unzähligen Beispiele, die man im Internet findet, habe ich mich für die Nutzung dieses Frameworks für diesen Workshop entschieden. Allerdings ist es meines Erachten nach, nicht immer das beste Framework. Oft gibt es für bestimmte Anwendungsfälle besser geeigente Frameworks, wie z.B. LlamaIndex. \n","Meine Kritikpunkte an LangChain sind: das Framework ist häufig inkonsistent und so hat man manchmal Situationen, wo man unterschiedliche Herangehensweisen für unterschiedliche Aufgaben benötigt, auch wenn man nur das Framework nutzt.\n","\n","Das Framework hat sich auch in den letzten Monaten stark verändert und so ist es manchmal etwas mühsam Beispielcode aus dem Internet wieder zum Laufen zu bringen, da vieles anders gelöst wird. Bitte seht es mir nach, wenn ich hier und da auch ins Straucheln komme! :)\n","\n","Wenn du dich selber ein wenig Schlau machen möchtest, so findest du hier eine Einführungsseite für LangChain: https://python.langchain.com/v0.2/docs/introduction/\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Wie ist LangChain aufgebaut?\n","\n","Sehen wir uns erstmal eine Grafik an...\n","\n","![LangChain Stack](https://python.langchain.com/v0.2/svg/langchain_stack_dark.svg)\n","\n","\n","Wie man sieht, ist LangChain ein Ökosystem aus vielen verschiedenen Tools und Framworks. Es gibt unzählige Community-Umsetzung von Adaptern und Tools und somit kann man LangChain beinahe mit allem Erdenkliche verbinden."]},{"cell_type":"markdown","metadata":{},"source":["## Übung #1 - Installation und erster Aufruf\n","Damit wir loslegen können, müssen wir zunächst alles was wir brauchen installieren. In der Python-Welt übernimmt das häufig der Paket-Manager `pip`.\n","Als erstes brauchen wir natürlich LangChain selbst."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install langchain langchain_openai python-dotenv"]},{"cell_type":"markdown","metadata":{},"source":["In diese Workshop nutzen wir die Modelle von OpenAI, also GPT-4o z.B.\n","\n","Damit wir das tun können, müssen wir einen API-Key bekommen. In diesem Workshop werde ich euch einen zur Verfügung stellen.\n","\n","Den API-Key fügen wir in die .env-Datei, in der Form OPENAI_API_KEY=..., ein.\n","\n","Lass uns ein erstes super einfaches Programm schreiben."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","from langchain_core.messages import HumanMessage, SystemMessage\n","from langchain_openai import ChatOpenAI, AzureChatOpenAI\n","from dotenv import load_dotenv\n","\n","load_dotenv()\n","os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n","os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n","os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n","\n","# model = ChatOpenAI(model=\"gpt-4o\")\n","model = AzureChatOpenAI(openai_api_version=\"2024-05-01-preview\", azure_deployment=\"gpt-4o\", temperature=0.5)\n","\n","messages = [\n","    SystemMessage(\"Du bist ein lustiger Chatbot, der auf Fragen antwortet aber sich so verhält als wäre er ein Minion.\"),\n","    HumanMessage(\"Schreibe eine Begrüßung für die Teilnehmer des KI-Agenten-Workshops.\"),\n","]\n","\n","model.invoke(messages)"]},{"cell_type":"markdown","metadata":{},"source":["Das hat hoffentlich bei dir funktioniert und du hast eine mehr oder weniger lustige Antwort bekommen.\n","\n","Was wir natürlich auch sehen, dass wir neben der Antwort eine Menge weiterer Informationen bekommen. Im Namen des LangChain Frameworks steck ja der Begriff _Chain_ also Kette. Wir werden gleich sehen, warum das so ist.\n","\n","Das Framework bietet nämlich die Verkettung von Verarbeitungsschritten an, die in einem sehr schlanken und gut lesbaren Code münden.\n","\n","Nehmen wir an, wir wollen nur die eigentliche Antwort ausgeben. Hierfür bietet LangChain einen _OutputParser_ an. Das ist eins von unzähligen Werkzeugen in diesem Framework.\n","\n","Der folgende Code zeigt, wie der Parser importiert und angelegt wird und dann in die Verabeitungskette eingefügt wird."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","\n","parser = StrOutputParser()\n","\n","chain = model | parser\n","\n","chain.invoke(messages)"]},{"cell_type":"markdown","metadata":{},"source":["Jetzt wird es relativ deutlich, wie LangChain \"tickt\". Durch das \"|\" Symbol können wir also unterschiedliche Bestandteile zu einer Kette zusammenfügen.\n","\n","Wir wollen uns bald an die Agenten wagen, aber bevor wir das tun, sollten wir uns ein wichtiges Konzept noch vorher ansehen.\n","\n","Wenn wir es mit KIs zu tun haben, müssen wir immer Prompts übergeben. In den wenigesten Fällen sind die Prompts fest verdrahtet und sind meist dynamisch gestaltet. Auch hiefür hat LangChain etwas im Petto, nämlich die _PromptTemplates_.\n","\n","Zwar kann man in Python recht einfach mit den sog. f-Strings Template-Strings sehr gut und einfach mit Werten befüllen aber die PromptTemplates fügen sich in die LangChain-Welt besser ein.\n","\n","Lass uns das vorherige Beispiel aufbohren und z.B. das Verhalten der KI nicht festverdrahten, sondern per Parameter übergeben.\n","\n","_(Das Beispiel ist eigentlich ein Musterbeispiel dafür, warum diese API manchmal etwas irritierend ist... mehr dazu auf der Tonspur...)_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","system_template = \"Du bist ein lustiger Chatbot, der auf Fragen antwortet aber sich so verhält als wäre er {person}.\"\n","\n","prompt_template = ChatPromptTemplate.from_messages(\n","    [(\"system\", system_template), (\"user\", \"{text}\")]\n",")\n","\n","# Direkte Ausführung des Templates als Beispiel, wie das Template funktioniert (Achtung: das hier ist kein Aufruf des KI... wir sezten nur das Template ein, um zu zeigen, wie es funktioniert.)\n","result = prompt_template.invoke({\"person\": \"ein verrückter Professor\", \"text\": \"Schreibe eine Begrüßung für die Teilnehmer des KI-Agenten-Workshops.\"})\n","\n","result"]},{"cell_type":"markdown","metadata":{},"source":["Jetzt fügen wir das Ganze zu einer Kette zusammen."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["chain = prompt_template | model | parser\n","\n","chain.invoke({\"person\": \"ein verrückter Professor\", \"text\": \"Schreibe eine Begrüßung für die Teilnehmer des KI-Agenten-Workshops.\"})"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":2}
