{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistenten und Agenten\n",
    "\n",
    "Dieser Abschnitt nennt sich ja _Assistenten und Agenten_... aber was ist das?\n",
    "\n",
    "## Assistenten\n",
    "Fangen wir mit den Assistenten an. Diese findet man unter unterschiedlichen Namen, je nachdem bei welchem Anbieter von KIs man sich befindet. So nenn man die Assistenten bei OpenAI (also ChatGPT) Custom-GPTs.\n",
    "Ein Assistent ist im Grunde genommen ein Chatbot, der eine bestimmte Instruktion erhalten hat. In dieser Instruktion wird aufgeführt, was der Assisten für eine Aufgabe hat. Das ist praktisch der System-Prompt für diesen Assistenten. Häufig bekommen die Assistenten aber mehr Möglichkeiten, so sind sie häufig in der Lage Dateien auszuwerten (per RAG). Manchmal können sie auch Code erzeugen und sogar ausführen um eine Aufgabe zu lösen. So können z.B. die Assistenten bei OpenAI mit der Option \"Code Interpreter\" Python-Code erstellen und in einer Sandbox-Umgebung ausführen. So kann man z.B. eine CSV-Datei (und viele andere Formate) hochladen und den Assistenten bitten ein Diagramm zu erzeugen, das man dann herunterladen kann. Das Diagramm wird dann meist mithilfe von Python-Bibliotheken erstellt.\n",
    "\n",
    "Aber wie unterscheidet sich ein Assistent von einem Agenten? Eigentlich gar nicht wirklich. Von Assistenten spricht man gerne, wenn man über eine Oberfläche den Assistenten konfigurieren kann. Es ist also praktisch ein einfacher Agent-Baukasten.\n",
    "\n",
    "![OpenAI Assistent](bilder/openai-assistent.png)\n",
    "\n",
    "Was hat das mit uns zu tun? Das ist doch ein \"Klicki-Bunti-Tool\"!!!111 Naja, das ist schon sehr nützlich für uns, denn die Assistenten können wir zum einen über API-Aufrufe ausführen und auch erstellen. D.h. wir haben hier einen sehr einfachen Weg um einen Assistenten in unsere Anwendung einzubauen. Wir müssen uns also nicht um Themen wie RAG oder Code-Ausführung Gedanken machen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasst uns einen Assistenten via API erstellen und anschliessend benutzen. Du kannst anstelle die API zu nutzen auch über https://platform.openai.com/assistants einen Assistenten erstellen. Einfach einen vernünftigen Namen aussuchen und bei _Instructions_ die Aufgabe des Assistenten beschreiben. Die Tools kannst du alle deaktiviert lassen, die brauchen wir jetzt erstmal nicht. Bei Modell gerne gpt-4o auswählen. Anschliessend brauchst du nur die Assistenten-ID zu kopieren.\n",
    "\n",
    "Das sind die _Instructions_ die ich nutze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"\"\"Du bist ein Assistent, der ein absoluter Experte in Sachen agiler Softwareentwicklung ist. \n",
    "Du hilfst dem Benutzer Userstories richtig zu formulieren. Du leitest den Benutzer an und fragst nach allen fehlenden Informationen. \n",
    "Wenn alle notwendigen Angaben gesammelt wurden, formulierst du die Userstory.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir fangen mit der Installation der Bibliotheken an und importieren dann ein Haufen Zeugs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_openai langchain_community python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir legen jetzt den Assistenten per API an. Falls du über die Oberfläche den Assistenten erstellt hast, dann überspringe diesen Punkt und gehe zum nächsten Code-Block.\n",
    "\n",
    "HINWEIS! Dieser Code funktioniert momentan nur direkt bei OpenAI! Für Azure müsste man direkt auf die Herstelle-API gehen. LangChain bietet stand jetzt nichts an (soweit ich weiß)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.agents.openai_assistant.base import OpenAIAssistantV2Runnable\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Die Instruction haben wir oben definiert!\n",
    "\n",
    "userstory_assistant = OpenAIAssistantV2Runnable.create_assistant(\n",
    "    name=\"Userstory Assistent\",\n",
    "    instructions=instruction,\n",
    "    tools=[],\n",
    "    model=\"gpt-4o\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante \"Assistent über Oberfläche\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userstory_assistant = OpenAIAssistantV2Runnable(assistant_id=\"asst_i0sYKWJ6Xr9YWQX7RKLfBruO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = userstory_assistant.invoke({\"content\": \"Ich brauche eine Userstory für das Anlegen eines neuen Benutzers.\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hinweis! Im Gegensatz zu den Chat-Endpunkt werden bei den Assistenten die Konversationen serverseitig gespeichert. Wenn du die Antwort genau studierst, dann siehst du, dass dort eine _thread\\_id_ geliefert wird. Diese ID identifiziert die Konversation.\n",
    "\n",
    "Hintergrund ist, dass wir dem Assistenten auch Dateien zur Verfügung stellen können. Da wäre es sehr ungünstig, wenn man bei jeder Frage die Dateien erneut übertragen müsste.\n",
    "\n",
    "### Was geht noch\n",
    "\n",
    "Den Assistenten können wir Tools an die Hand geben. Aber das sparen wir uns ein wenig auf, denn wir kommen langsam zu den Agenten. Übrigens kannst du den Assistenten oben auch als LangChain-Agent behandeln. Dazu muss man als Parameter _as_agent=True_ übergeben.\n",
    "Die Agenten schauen wir uns in den folgenden Abschnitten an!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier geht es zum nächsten Abschnitt: Tools: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ki-zeitalter/ai-agent-workshop/blob/main/05_erste_tools.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
