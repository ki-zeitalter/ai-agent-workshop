{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real World Example!\n",
    "\n",
    "Wenn man nur die Grundkonzpete gesehen hat, dann wird es auf Anhieb nicht klar, was man mit diesem Framework anfangen kann. Deswegen wollen wir uns ein einfaches Beispiel ansehen, das einen echten Usecase darstellen kann.\n",
    "Und wie wir gesehen haben, handelt es sich um ein Workflow-System. Deswegen wird das Beispiel natürlich einen Workflow nutzen...\n",
    "\n",
    "Das Szenario: Wir machen einen KI-Chatbot für ein Restaurant. Dieser Chatbot soll Anfragen in natürlicher Sprache entgegen nehmen. Über den Chatbot kann der Benutzer Bestellungen abgeben oder Informationen wie z.B. Öffnungszeiten abrufen.\n",
    "\n",
    "Lösung: Wir nutzen ein Agenten-System. Erstmal brauchen wir einen Agenten, der die Aufgabe hat die Absicht des Benutzers erkennt. Wir machen uns das Leben hier einfach, d.h. erlaubt ist entweder bestellen oder Infos abrufen.\n",
    "Wenn der User Infos haben möchte, dann routen wir zu dem Info-Assistenten, der die Anfrage beantwortet.\n",
    "\n",
    "Im Falle einer Bestellung müssen wir prüfen, ob wir alle Angaben haben. Wir müssen zum einen wissen, was der Benutzer bestellen möchte und außerdem wohin das Essen geliefert werden soll. Hierfür nutzen wir auch einen Agenten zur Prüfung. Falls Angaben fehlen, wird der Benutzer danach gefragt.\n",
    "\n",
    "Wenn alles OK ist, dann wird der Bestell-Agent beauftrag die Bestellung für die Küche aufzubereiten. Dazu wird er ein Tool nutzen. In einer echten Anwendung wäre das z.B. eine Datenbank. Wir machen es hier aber recht einfach, in dem das Tool eine formatierte Ausgabe macht, in der alle wichtigen Angaben für die Küche enhalten sind.\n",
    "\n",
    "Zu guter Letzt wird der Auftrag bestätigt und der Prozess ist beendet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schauen wir uns das als Diagramm mal an...\n",
    "\n",
    "![Diagramm](./bilder/agent-flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasst uns die Anwendung sukzessive aufbauen. Wir fangen erstmal mit der üblichen Initialisierung und Installation an. Wir legen dann ein Datenmodell (_State_) an.\n",
    "Dann legen wir jeden Agenten als Funktion (_Node_) an. Wir legen ausserdem das Tool an.\n",
    "\n",
    "Zuletzt erstellen wir den Graph und verknüpfen alles zu einem Gesamtsystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph langchain_openai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "# model = ChatOpenAI(model=\"gpt-4o\")\n",
    "model = AzureChatOpenAI(openai_api_version=\"2024-05-01-preview\", azure_deployment=\"gpt-4o\", temperature=0.5)\n",
    "\n",
    "#model = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    missing_info: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_user(state: State):\n",
    "    # Hier fragen wir den Nutzer, was er tun möchte\n",
    "    user_input = input(\"Wilkommen! Bitte geben Sie hier Ihr Anliegen ein: \")\n",
    "    state[\"messages\"].append(HumanMessage(user_input))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intent-Agent\n",
    "intent_agent_system_template = \"\"\"Du bist ein Agent eines Restaurant-Bestell-Systems. Deine Aufgabe ist es die Absicht des Nutzers zu erkennen. \n",
    "Der Nutzer kann zwei Absichten haben: eine Bestellung aufgeben oder Informationen zu dem Restaurant erhalten.\n",
    "Bitte erkenne die Absicht des Nutzers und gib sie an. Die möglichen Absichten sind:\n",
    "'info' oder 'order'. Antworte nur mit 'info' oder 'order'.\n",
    "\"\"\"\n",
    "\n",
    "intent_agent_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", intent_agent_system_template), (\"user\", \"Hier ist die Anfrage des Nutzers: {text}\")]\n",
    ")\n",
    "\n",
    "intent_agent_chain = intent_agent_prompt_template | model | StrOutputParser()\n",
    "\n",
    "def intent_agent(state: State):\n",
    "    # Wir beauftragen die KI die Absicht des Nutzers zu erkennen: \"info\" oder \"order\"\n",
    "    result = intent_agent_chain.invoke(state[\"messages\"])\n",
    "    print(f\"Intent: {result}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_agent_system_template = \"\"\"Du bist ein Agent eines Restaurant-Bestell-Systems. Deine Aufgabe ist es Informationen über das Restaurant zu geben. \n",
    "Bitte gib die Informationen an, die der Nutzer benötigt.\n",
    "\n",
    "Restaurant-Informationen:\n",
    "- Name: Restaurant \"Zur wildgewordenen KI\"\n",
    "- Adresse: KI-Straße 42, 12345 KI-Stadt\n",
    "- Telefonnummer: 01234 567890\n",
    "- Öffnungszeiten: Montag bis Freitag von 10 bis 22 Uhr\n",
    "- Speisekarte: Pizza, Pasta, Salate, Desserts\n",
    "- Lieferung: Ja, Lieferung möglich\n",
    "- Reservierung: Ja, Reservierung möglich\n",
    "- Sonstiges: WLAN, Barrierefreiheit\n",
    "\"\"\"\n",
    "\n",
    "info_agent_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", info_agent_system_template), (\"user\", \"Hier ist die Anfrage des Nutzers: {text}\")]\n",
    ")\n",
    "\n",
    "info_agent_chain = info_agent_prompt_template | model | StrOutputParser()\n",
    "\n",
    "def info_agent(state: State):\n",
    "    # Dieser Agent beantwortet die Frage. Der Agent hat die notwendigen Informationen in seinem System-Prompt, um die Frage zu beantworten.\n",
    "    result = info_agent_chain.invoke(state[\"messages\"])\n",
    "    print(f\"Info: {result}\")\n",
    "\n",
    "    state[\"messages\"].append(AIMessage(result))\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def accept_order_agent(state: State):\n",
    "    print(\"Bestellung annehmen\")\n",
    "    # Dieser Agent nimmt die Bestellung entgegen. Hier passiert erstmal nichts. In einer echten Anwendung würde hier die Bestellung gespeichert.\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_check_agent_system_template = \"\"\"Du bist ein Agent eines Restaurant-Bestell-Systems. Deine Aufgabe ist es die Bestellung des Kunden auf Vollständigkeit zu prüfen.\n",
    "Zu einer Bestellung gehören folgende Informationen:\n",
    "- Was soll bestellt werden?\n",
    "- Wohin soll die Bestellung geliefert werden?\n",
    "- Wann soll die Bestellung geliefert werden?\n",
    "\n",
    "Wenn etwas fehlt, dann formuliere eine Frage, die den Nutzer dazu auffordert, die fehlenden Informationen anzugeben.\n",
    "Wenn nichts fehlt, antworte mit 'Alles vollständig'.\n",
    "\"\"\"\n",
    "\n",
    "order_check_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", order_check_agent_system_template), (\"user\", \"Hier ist die Bestellung des Nutzers: {text}\")]\n",
    ")\n",
    "\n",
    "order_check_chain = order_check_prompt_template | model | StrOutputParser()\n",
    "\n",
    "def order_check_agent(state: State):\n",
    "    print(\"Bestellung überprüfen\")\n",
    "    # Dieser Agent überprüft, ob alle Angaben für die Bestellung vorhanden sind. Wenn nicht, dann antwortet er mit \"incomplete\". Wenn ja, dann antwortet er mit \"complete\".\n",
    "    # Die Info, die noch fehlt, wird in der state gespeichert.\n",
    "\n",
    "    result = order_check_chain.invoke(state[\"messages\"])\n",
    "    print(f\"Order check: {result}\")\n",
    "\n",
    "    if result.startswith(\"Alles vollständig\"):\n",
    "        return \"complete\"\n",
    "\n",
    "    state[\"missing_info\"] = result\n",
    "\n",
    "    return \"incomplete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_info_agent(state: State):\n",
    "    print(\"Fehlende Information anfordern\")\n",
    "    # Dieser Agent fragt nach der fehlenden Information.\n",
    "    # Hier fragen wir den Nutzer, was er tun möchte\n",
    "    user_input = input(f\"Es tut mir leid aber folgende Information fehlt noch: {state['missing_info']}: \")\n",
    "    state[\"messages\"].append(HumanMessage(user_input))\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "order_create_system_template = \"\"\"Du bist ein Agent eines Restaurant-Bestell-Systems. Deine Aufgabe ist es die Bestellung im Restaurant-Bestell-System zu erstellen.\n",
    "\"\"\"\n",
    "\n",
    "order_create_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", order_create_system_template), (\"user\", \"Erstelle die Bestellung mit den folgenden Informationen: {text}\")]\n",
    ")\n",
    "\n",
    "order_create_chain = order_create_prompt_template | model | StrOutputParser()\n",
    "\n",
    "@tool\n",
    "def create_order(meal_orders: list[str], delivery_address: str, delivery_time: str):\n",
    "    \"\"\"Erstellt eine Bestellung im Restaurant-Bestell-System.\"\"\"\n",
    "\n",
    "    print(\"Bestellung:\")\n",
    "    print(f\"Gerichte: {meal_orders}\")\n",
    "    print(f\"Lieferadresse: {delivery_address}\")\n",
    "    print(f\"Lieferzeit: {delivery_time}\")\n",
    "\n",
    "    return \"Bestellnummer: 47110815\"\n",
    "\n",
    "\n",
    "tools = [create_order]\n",
    "\n",
    "model.bind_tools(tools)\n",
    "\n",
    "def create_order_agent(state: State):\n",
    "    print(\"Bestellung erstellen\")\n",
    "    # Dieser Agent erstellt die Bestellung mit dem Tool.\n",
    "\n",
    "    result = order_create_chain.invoke(state[\"messages\"])\n",
    "    print(f\"Order create: {result}\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"ask\", ask_user)\n",
    "graph_builder.add_node(\"info\", info_agent)\n",
    "graph_builder.add_node(\"accept_order\", accept_order_agent)\n",
    "graph_builder.add_node(\"missing_info_agent\", missing_info_agent)\n",
    "graph_builder.add_node(\"create_order\", create_order_agent)\n",
    "\n",
    "graph_builder.add_edge(START, \"ask\")\n",
    "graph_builder.add_conditional_edges(\"ask\", intent_agent, { \"info\": \"info\", \"order\": \"accept_order\" })\n",
    "graph_builder.add_conditional_edges(\"accept_order\", order_check_agent, { \"complete\": \"create_order\", \"incomplete\": \"missing_info_agent\" })\n",
    "graph_builder.add_conditional_edges(\"missing_info_agent\", order_check_agent, { \"complete\": \"create_order\", \"incomplete\": \"missing_info_agent\" })\n",
    "graph_builder.add_edge(\"create_order\", END)\n",
    "graph_builder.add_edge(\"info\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke({\"messages\": []})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
