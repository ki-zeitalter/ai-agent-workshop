{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# KI Agenten - Workshop\n","\n","## Worum geht es und was haben wir vor?\n","\n","KI Agenten sind laut vielen Experten das nächste große Ding in Sachen KIs. Ganz unabhängig davon, ob das stimmt, können (autonome) KI Agenten hilfreich sein und es lohnt sich, sich damit auseinander zu setzen.\n","Meiner Einschätzung nach erweitern KI Agenten das Spektrum an Werkzeugen, die man zum Lösen von Aufgaben benötigt. Diese ermöglichen auch Aufgaben zu löschen, die zuvor eigentlich nicht automatisierbar waren.\n","\n","Dennoch, bei aller Euphorie, muss man sagen, dass Stand jetzt autonome Agenten noch in den Kinderschuhen stecken und häufig Fehler begehen. Komplexe Aufgaben sind also noch in weiter Ferne.\n","\n","Heute schauen wir uns an, wie man Agenten erstellt und wozu sie gut sein könnten. Wir beginnen mit sehr einfachen Formen und steigern uns dann und setzen das Agentenframework LangGraph ein.\n","\n","\n","## Was sind denn Agenten überhaupt?\n","\n","Die Definitionen, was ein Agent ist, gehen wie so oft stark auseinander. Wo sich die meisten jedoch einig sind, ist dass wenn man der KI Werkzeuge zur Verfügung stellt und die KI selbst entscheidet, wann sie diese Werkzeuge einsetzen möchte, die erste Stufe eines Agenten erreicht ist.\n","Es gibt aber je nach Definition auch Agenten ohne Werkzeuge, also z.B. Agenten, die durch Prompting-Techniken erzeugt werden. \n","\n","Meist weist man einem Agenten eine Rolle zu, z.B. Organisator, Qualitätssicherer, Coder usw. Der Hintergrund ist der, dass Sprachmodelle häufig besser performen, wenn man sie in eine Rolle versetzt. In Agentensystemen, hat man also meist ein paar Agenten mit unterschiedlichen Rollen.\n","In diesen Systemen tauschen die Agenten Daten aus, sei es dadurch, dass sie einen Prompt mit allen notwenigen Informationen bekommen und die Antwort wird z.B. einen anderen Agenten übergeben, oder z.B. durch einen gemeinsamen Speicher, auf den jeder Agent Zugriff hat.\n","\n","Gibt man einer KI die Möglichkeit Werkzeuge zu nutzen, läuft das häufig so ab, dass die KI die Ausführung anfragt und jemand oder etwas führt das Werkzeug aus und übergibt das Ergebnis wiederum an die KI, die dann damit arbeiten kann. D.h. die KI kann nicht einfach selbst etwas ausführen. Allerings bieten Agentensysteme die Möglichkeit an, dass diese Tool-Anfragen automatisch ausgeführt werden, ohne dass ein Mensch die Ausführung genehmigen muss oder gar selbst ausführen muss. Hier sprechen wir dann von *autonomen* Agenten. Häufig kombiniert man das aber mit _Human-In-The-Loop_ Ansätzen. D.h. bei kritischen Ausführungen wird ein Mensch erstmal um Erlaubnis gebeten. Auch wird das genutzt um z.B. zu entscheiden, wie etwas weitergehen soll, im Sinne von entweder Weg A, B oder C z.B. Oder um weitere Informationen abzufragen.\n","\n","Bei Systemen mit mehreren Agenten kann man für jeden Agent unterschiedliche Modelle verwenden. So kann man für jede Aufgabe das beste Modell auswählen. Während z.B. der Organisator-Agent ein Modell einsetzt, das gut logisch kombinieren kann, setzt der Coder ein Modell ein, das besonders gut Code produzieren kann.\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Es wird Zeit anzufangen...\n","\n","Starten wir mit einer sehr knappen und schnellen LangChain-Einführung. Ach ja, dieser Workshop nutzt Python. In der Welt der KIs und Datascience ist Python quasi die Standardsprache. Keine Sorge... wenn du irgendeine andere Programmiersprache kannst, wie Java, TypeScript, C# usw. kannst, dann wird es für dich kein großes Problem sein Python zu verstehen und anzuwenden. Da der Workshop voll mit Beispielen ist, sollte das Meiste was man braucht irgendwo zu sehen sein.\n","\n","### Was ist LangChain?\n","LangChain ist ein Framework um programmatisch mit KIs zu kommunizieren. In seiner einfachsten Form ist es eine einheitliche API für alle möglichen Sprachmodelle. Zusätzlich bietet es zahlreiche Utilities und Helferlein für alle erdenklichen Aufgaben rund um das Thema KI. Der Vorteil bei der Nutzung von solchen Frameworks ist, dass man sich weniger stark an den Anbieter von dem jeweiligen KI-Modells bindet, die ja meist ihre eigenen APIs anbieten. So kann man sehr leicht bestehenden Code auf ein anderes Modell jagen, ohne dabei viel anpassen zu müssen.\n","\n","Wenn du dich selber ein wenig Schlau machen möchtest, so findest du hier eine Einführungsseite für LangChain: https://python.langchain.com/v0.2/docs/introduction/\n","\n","![LangChain Stack](https://python.langchain.com/v0.2/svg/langchain_stack_dark.svg)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Übung #1 - Installation und erster Aufruf\n","Damit wir loslegen können, müssen wir zunächst alles was wir brauchen installieren. In der Python-Welt übernimmt das häufig der Paket-Manager `pip`.\n","Als erstes brauchen wir natürlich LangChain selbst."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: langchain in ./.venv/lib/python3.11/site-packages (0.2.5)\n","Collecting langchain_openai\n","  Downloading langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: python-dotenv in ./.venv/lib/python3.11/site-packages (1.0.1)\n","Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.11/site-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.11/site-packages (from langchain) (2.0.31)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.11/site-packages (from langchain) (3.9.5)\n","Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in ./.venv/lib/python3.11/site-packages (from langchain) (0.2.9)\n","Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.11/site-packages (from langchain) (0.2.1)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.11/site-packages (from langchain) (0.1.81)\n","Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.11/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.11/site-packages (from langchain) (2.7.4)\n","Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.11/site-packages (from langchain) (2.32.3)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.venv/lib/python3.11/site-packages (from langchain) (8.4.1)\n","Collecting openai<2.0.0,>=1.26.0 (from langchain_openai)\n","  Downloading openai-1.35.3-py3-none-any.whl.metadata (21 kB)\n","Collecting tiktoken<1,>=0.7 (from langchain_openai)\n","  Using cached tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.6 kB)\n","Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n","Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n","Collecting anyio<5,>=3.5.0 (from openai<2.0.0,>=1.26.0->langchain_openai)\n","  Using cached anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n","Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.26.0->langchain_openai)\n","  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n","Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.26.0->langchain_openai)\n","  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n","Collecting sniffio (from openai<2.0.0,>=1.26.0->langchain_openai)\n","  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting tqdm>4 (from openai<2.0.0,>=1.26.0->langchain_openai)\n","  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n","Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.12.2)\n","Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.18.4 in ./.venv/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.2)\n","Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n","Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n","  Downloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai)\n","  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai)\n","  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n","Downloading langchain_openai-0.1.9-py3-none-any.whl (40 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.3/40.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading openai-1.35.3-py3-none-any.whl (327 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.4/327.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hUsing cached tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl (907 kB)\n","Using cached anyio-4.4.0-py3-none-any.whl (86 kB)\n","Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n","Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n","Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n","Downloading regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl (278 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.3/278.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hUsing cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n","Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n","Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n","Installing collected packages: tqdm, sniffio, regex, h11, distro, tiktoken, httpcore, anyio, httpx, openai, langchain_openai\n","Successfully installed anyio-4.4.0 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain_openai-0.1.9 openai-1.35.3 regex-2024.5.15 sniffio-1.3.1 tiktoken-0.7.0 tqdm-4.66.4\n"]}],"source":["!pip install langchain langchain_openai python-dotenv"]},{"cell_type":"markdown","metadata":{},"source":["In diese Workshop nutzen wir die Modelle von OpenAI, also GPT-4o z.B.\n","\n","Damit wir das tun können, müssen wir einen API-Key bekommen. In diesem Workshop werde ich euch einen zur Verfügung stellen.\n","\n","Den API-Key fügen wir in die .env-Datei, in der Form OPENAI_API_KEY=..., ein.\n","\n","Lass uns ein erstes super einfaches Programm schreiben."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["AIMessage(content='Bello! Tulaliloo ti amo! Minion-Bob hier, bereit für etwas Bananalicious Spaß beim KI-Agenten-Workshop! Wir werden zusammen viel \"Bello!\" sagen und viele \"Bananas\" entdecken! Lasst uns anfangen und viel \"Gelato\" haben! Banana!', response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 55, 'total_tokens': 116}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_9cb5d38cf7', 'finish_reason': 'stop', 'logprobs': None}, id='run-70473ab4-d7f6-4e6d-8ab7-2ce82e75f71d-0', usage_metadata={'input_tokens': 55, 'output_tokens': 61, 'total_tokens': 116})"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","from langchain_core.messages import HumanMessage, SystemMessage\n","from langchain_openai import ChatOpenAI\n","from dotenv import load_dotenv\n","\n","load_dotenv()\n","os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n","\n","model = ChatOpenAI(model=\"gpt-4o\")\n","\n","messages = [\n","    SystemMessage(\"Du bist ein lustiger Chatbot, der auf Fragen antwortet aber sich so verhält als wäre er ein Minion.\"),\n","    HumanMessage(\"Schreibe eine Begrüßung für die Teilnehmer des KI-Agenten-Workshops.\"),\n","]\n","\n","model.invoke(messages)"]}],"metadata":{"kernelspec":{"display_name":".venv","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":2}
